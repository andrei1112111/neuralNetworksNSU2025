{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Задание 1\n",
    "\n",
    "Аудио длинной в 1 секунду и частотой дискретизации в 16 кГЦ загоняем в SIFT с окном в 25 мс и шагом в 10 мс.\\\n",
    "Требуется найти количество поместившихся в него временных окон"
   ],
   "id": "46c55cbcefe44f1d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T09:13:41.127883Z",
     "start_time": "2025-04-18T09:13:41.120320Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def count_stft_frames(sample_rate, sample_duration, window_size, step_size):\n",
    "    # переводим из секунд в количество семплов\n",
    "    # длинна в секундах на частоту дискретизации в герцах(семплов в секунду)\n",
    "    window_size = window_size * sample_rate\n",
    "    step_size = step_size * sample_rate\n",
    "\n",
    "    samples = sample_duration * sample_rate  # кличество семплов в аудио\n",
    "\n",
    "    # считаем количество окон (сколько целых шагов нужно чтобы дойти до последнего + 1 последний)\n",
    "    frames = (samples - window_size) // step_size + 1  # -> получем только окна которые полностью помещаются в сигнал\n",
    "\n",
    "    return int(frames)  # frames уже целое из за целочисленного деления"
   ],
   "id": "7eda226cd403c4af",
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-18T09:13:42.722730Z",
     "start_time": "2025-04-18T09:13:42.719419Z"
    }
   },
   "source": [
    "sample_rate = 16000  # частота дискретизации в герцах\n",
    "sample_duration = 1  # длительность сигнала в секундах\n",
    "window_size = 0.025  # длина окна в секундах\n",
    "step_size = 0.010  # шаг окна в секундах"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T09:13:44.042565Z",
     "start_time": "2025-04-18T09:13:44.038674Z"
    }
   },
   "cell_type": "code",
   "source": [
    "frames = count_stft_frames(sample_rate, sample_duration, window_size, step_size)\n",
    "\n",
    "print(f\"Временных окон: {frames}\")"
   ],
   "id": "8b8dee6f8974655c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Временных окон: 98\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Задание 2\n",
    "\n",
    "Модель: y_pred = wx + b\\\n",
    "Функция потерь: L = (y_pred - y_true)^2\n",
    "\n",
    "вес w = 2.0 и смещение b = 1.0\n",
    "\n",
    "на входе x = 3\\\n",
    "ожидаемый предикт y_true = 10\n",
    "\n",
    "Требуется посчитать градиенты для w и b"
   ],
   "id": "727c458ec91dc655"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T09:13:49.835488Z",
     "start_time": "2025-04-18T09:13:49.831739Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# модель y_pred = wx + b\n",
    "class Model:\n",
    "    def __init__(self, w, b):\n",
    "        self.w = w\n",
    "        self.b = b\n",
    "\n",
    "    def forward(self, x):  # вычисление линейного выражения (предикта)\n",
    "        y = self.w * x + self.b\n",
    "        return y\n",
    "\n",
    "    def backward(self, x, y_true):\n",
    "        y_pred = self.forward(x)\n",
    "\n",
    "        # производная по x от (wx+b - y_true)^2 = 2*(wx+b - y_true) * (производная по w от (wx+b - y_true) которая равна x)\n",
    "        dL_dw = 2 * (y_pred - y_true) * x\n",
    "\n",
    "        # производная по x от (wx+b - y_true)^2 = 2*(wx+b - y_true) * (производная по b от (wx+b - y_true) которая равна 1)\n",
    "        dL_db = 2 * (y_pred - y_true)\n",
    "\n",
    "        return dL_dw, dL_db"
   ],
   "id": "5ca01307b5e12cd7",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T09:13:51.830262Z",
     "start_time": "2025-04-18T09:13:51.826319Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# лосс L = (y_pred - y_true)^2\n",
    "def loss(model, x, y):\n",
    "    L = (model.forward(x) - y) ** 2\n",
    "\n",
    "    return L"
   ],
   "id": "f9be6cde23df7e7d",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T09:13:52.845381Z",
     "start_time": "2025-04-18T09:13:52.842820Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x = 3\n",
    "y_true = 10"
   ],
   "id": "721b5f323b72827b",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T09:13:53.898844Z",
     "start_time": "2025-04-18T09:13:53.895867Z"
    }
   },
   "cell_type": "code",
   "source": "model = Model(2.0, 1.0)",
   "id": "451b19a60b5caa17",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T09:13:54.998880Z",
     "start_time": "2025-04-18T09:13:54.995448Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# вычислим лосс для предикта модели\n",
    "L = loss(model, x, y_true)\n",
    "print(L)"
   ],
   "id": "25d3dbea4027b9ad",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.0\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T09:13:57.008123Z",
     "start_time": "2025-04-18T09:13:57.004753Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# найдем частные производные функции потерь по обучаемым параметрам\n",
    "# dL по dw и dL по db\n",
    "dL_dw, dL_db = model.backward(x, y_true)\n",
    "print(\"dL по dw:\", dL_dw)\n",
    "print(\"dL по db:\", dL_db)"
   ],
   "id": "1060d745e9348703",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dL по dw: -18.0\n",
      "dL по db: -6.0\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Задание 3\n",
    "\n",
    "Собираемся обучить модель для решения задачи распознавания речи.\n",
    "\n"
   ],
   "id": "78c10175a09ed61f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "a) Начнем с загрузки аудио и парсинга расшифровки. Приведем аудио к формату с которым может работать модель (разделим на термы нужной длинны)\n",
    "   Можно нормализовать громкость звука и добавить шумоподавление чтобы модели было легче рязделять и понимать слова\n",
    "\n",
    "b) Будем проходить по монологам и разбивать термы так чтобы их длинна не превышала 30 секунд\n",
    "   Т.е монолог одного говорящего поделим на термы по 30 секунд разбивая аудио по словам с помощью librosa.effects.split\n",
    "   Каждый терм дополним тишиной до 30 секунд\n",
    "   Для каждого получившегося терма подберем слова из исходного (Каждая 30 секундная часть будет содержать слова которые в нее входят)\n",
    "\n",
    "c) Можно использовать добавление шума разных частот к аудио, уменьшение / увеличение громкости, добавление звуковых эффектов например реверберации\n",
    "\n",
    "d) Разделить датасет на трейн и валидацию для отслеживания реальных метрик\n",
    "   Использовать аугментации для увеличения количества семплов в датасете\n",
    "   Использовать регуляризации внутри модели. Попробовать дообучить предобученные модели\n",
    "\n",
    "e) Для Whisper сохраним описания в формате текста и временных меток для аудио файла\n",
    "\"\"\""
   ],
   "id": "550891a4b00b4ebe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# посмотрим на формат расшифровки:\n",
    "\"\"\"\n",
    "{\n",
    "    \"schemaVersion\": \"2.0\",\n",
    "    \"monologues\": [\n",
    "        {\n",
    "            \"speaker\": {\n",
    "                \"id\": \"0\",\n",
    "                \"name\": \"\"\n",
    "            },\n",
    "            \"start\": 0.0,\n",
    "            \"end\": 33.221,\n",
    "            \"terms\": [\n",
    "                {\n",
    "                    \"text\": \"Еще большую тревогу вызывает у меня американская политика в отношении Ближнего Востока, которая исторически, а особенно после 11 сентября 2011 года, была излишне сфокусирована на подавлении любых политических волнений во имя препятствования «исламскому фундаментализму» – выражение, которое использовал практически каждый режим. Беда в том, что уничтожение исламистов увеличивает их численность; в любом случае Запад и его автократические арабские союзники лишь усилили исламских фундаменталистов, когда загнали их в подполье.\",\n",
    "                    \"start\": 0.0,\n",
    "                    \"end\": 33.221,\n",
    "                    \"text_normalized\": \"еще большую тревогу вызывает у меня американская политика в отношении ближнего востока которая исторически а особенно после одиннадцатого сентября две тысячи одиннадцатого года была излишне сфокусирована на подавлении любых политических волнений во имя препятствования исламскому фундаментализму выражение которое использовал практически каждый режим беда в том что уничтожение исламистов увеличивает их численность в любом случае запад и его автократические арабские союзники лишь усилили исламских фундаменталистов когда загнали их в подполье \"\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        ...\n",
    "\"\"\"\n",
    "# Будем разделять по монологам. Монологи по термам.\n",
    "# Каждый терм состоит из полей text_normalized представляющего собой речь нормализованную так как она произносится по словам. Т.е вырезаны все знаки припенания и числа находятся в форме слов.\n",
    "# Также есть границы терма"
   ],
   "id": "b8681ad735274971",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "\n",
    "import json\n",
    "import os"
   ],
   "id": "91d1d2807fb334cb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Параметры\n",
    "AUDIOT_FILE = \"diff_spks_lvl_1_0_0_0_05.ogg\"\n",
    "TRANSCRIPT_FILE = \"diff_spks_lvl_1_0_0_0_05.json\"\n",
    "MONOLOGUES_DIR = \"monologues\"\n",
    "TERM_DURATION = 30.0\n",
    "SAMPLE_RATE = 16000"
   ],
   "id": "ac9dbddcb680b669",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# загружаем аудио и вычисляем частоту дискретизации\n",
    "audio, SAMPLE_RATE = librosa.load(AUDIOT_FILE, sr=SAMPLE_RATE)  # меняет частоту дискретизации на SAMPLE_RATE\n",
    "\n",
    "# загружаем расшифровку\n",
    "with open(TRANSCRIPT_FILE, 'r', encoding='utf-8') as f:\n",
    "    transcript = json.load(f)\n",
    "\n",
    "# создаем папку для монологов с термами длинной в TERM_DURATION и приложенным к ним расшифровкам\n",
    "os.makedirs(MONOLOGUES_DIR, exist_ok=True)"
   ],
   "id": "959757926b0f6575",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# аугментация по громкости\n",
    "def aug_volume(audio, mindb=5, maxdb=5):\n",
    "    # случайно измененяем громкось в диапозоне mindb : maxdb\n",
    "    gain_db = np.random.uniform(mindb, maxdb)\n",
    "    audio = librosa.effects.preemphasis(audio, coef=gain_db)\n",
    "\n",
    "    return audio\n",
    "\n",
    "# аугментация по шуму\n",
    "def aug_noise(audio, noise_level=0.005):\n",
    "    # добавляем белый шум\n",
    "    noise = np.random.normal(0, noise_level, audio.shape)\n",
    "    audio = audio + noise\n",
    "\n",
    "    return audio\n",
    "\n",
    "# применяем набор аугментаций к аудио\n",
    "def aug(audio):\n",
    "    audio_augms = [audio]  # вместе с оригиналом\n",
    "\n",
    "    for aug in [aug_volume, aug_noise]:\n",
    "        # Изменение громкости\n",
    "        audio = aug(audio)\n",
    "        audio_augms.append(audio)\n",
    "\n",
    "    return audio_augms\n"
   ],
   "id": "998be29f36eb27e5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for monolog_index, monolog in enumerate(transcript[\"monologues\"]):\n",
    "    # создаем отдельные папки для каждого монолога\n",
    "    monolog_path = f\"{MONOLOGUES_DIR}/monologue_{monolog_index}\"\n",
    "    os.makedirs(monolog_path, exist_ok=True)\n",
    "\n",
    "    # создадим описание монолога и будем заносить в него новые обработанные термы\n",
    "    monolog_discr = {\"speaker\": monolog[\"speaker\"], \"start\": monolog[\"start\"], \"end\": monolog[\"end\"], \"terms\": []}\n",
    "\n",
    "    term_index = 0\n",
    "    for term in monolog[\"terms\"]:\n",
    "        # Перевод время в количество сэмплов\n",
    "        start_sample = int(term[\"start\"] * SAMPLE_RATE)\n",
    "        end_sample = int(term[\"end\"] * SAMPLE_RATE)\n",
    "        required_samples = int(TERM_DURATION * SAMPLE_RATE)\n",
    "\n",
    "        # обрежем аудио\n",
    "        term_audio = audio[start_sample:end_sample]\n",
    "\n",
    "        # если терм вписывается в TERM_DURATION будем сохранять его как есть\n",
    "        if term[\"end\"] - term[\"start\"] <= TERM_DURATION:\n",
    "            # дополним его тишиной до TERM_DURATION\n",
    "            if len(term_audio) < required_samples:\n",
    "                padding = np.zeros(required_samples - len(term_audio))\n",
    "                term_audio = np.concatenate([term_audio, padding])\n",
    "\n",
    "            # и сохраним аугментации для терма\n",
    "            audio_paths = []\n",
    "            for aug_index, augm_audio in enumerate(aug(term_audio)):\n",
    "                audio_path = f\"{monolog_path}/term_{term_index}_aug{aug_index}.wav\"\n",
    "                audio_paths.append(audio_path)\n",
    "                sf.write(audio_path, augm_audio, SAMPLE_RATE)\n",
    "\n",
    "            # добавляем описание терма для Whisper\n",
    "            monolog_discr[\"terms\"].append({\n",
    "                \"audio_path\": audio_paths[0],  # берем первый аудиофайл (или добавляем все для аугментаций)\n",
    "                \"start\": term[\"start\"],\n",
    "                \"end\": term[\"end\"],\n",
    "                \"text\": term[\"text_normalized\"]  # Используем нормализованный текст для обучения\n",
    "            })\n",
    "\n",
    "        # Если терм не вписывается в TERM_DURATION, будем делить его на несколько частей\n",
    "        else:\n",
    "            terms = []\n",
    "            term_words = term[\"text_normalized\"].split()\n",
    "            cur_term_words = []\n",
    "            terms_start = term[\"start\"]\n",
    "            terms_end = term[\"start\"]\n",
    "\n",
    "            segments = librosa.effects.split(term_audio, top_db=20)  # разделяем на сегменты по уровням громкости\n",
    "            for segment_index, segment in enumerate(segments):  # проходим по сегментам-словам\n",
    "                # Вычисляем начало и конец сегмента\n",
    "                segment_start_sample = segment[0]\n",
    "                segment_end_sample = segment[1]\n",
    "                segment_start_time = (segment_start_sample / SAMPLE_RATE) + term[\"start\"]\n",
    "                segment_end_time = (segment_end_sample / SAMPLE_RATE) + term[\"start\"]\n",
    "\n",
    "                # Добавляем слово текущему терму, если длина терма со словом меньше TERM_DURATION\n",
    "                if terms_end - terms_start + (segment_end_time - segment_start_time) <= TERM_DURATION:\n",
    "                    terms.append(segment)\n",
    "                    term_words.append(term_words[0])\n",
    "                    term_words = term_words[1:]\n",
    "                    terms_end = segment_end_time\n",
    "\n",
    "                # Если слово не влезет в терм, то запишем текущий и начнем новый\n",
    "                if terms_end - terms_start + (segment_end_time - segment_start_time) > TERM_DURATION or segment_index == len(segments) - 1:\n",
    "                    start_sample = int(terms_start * SAMPLE_RATE)\n",
    "                    end_sample = int(terms_end * SAMPLE_RATE)\n",
    "                    required_samples = int(TERM_DURATION * SAMPLE_RATE)\n",
    "\n",
    "                    chunk_audio = audio[start_sample:end_sample]\n",
    "\n",
    "                    # дополним его тишиной до TERM_DURATION\n",
    "                    if len(chunk_audio) < required_samples:\n",
    "                        padding = np.zeros(required_samples - len(chunk_audio))\n",
    "                        chunk_audio = np.concatenate([chunk_audio, padding])\n",
    "\n",
    "                    # и сохраним аугментации для терма\n",
    "                    audio_paths = []\n",
    "                    for aug_index, augm_audio in enumerate(aug(chunk_audio)):\n",
    "                        audio_path = f\"{monolog_path}/term_{term_index}_aug{aug_index}.wav\"\n",
    "                        audio_paths.append(audio_path)\n",
    "                        sf.write(audio_path, augm_audio, SAMPLE_RATE)\n",
    "\n",
    "                    # добавляем описание терма для Whisper\n",
    "                    monolog_discr[\"terms\"].append({\n",
    "                        \"audio_path\": audio_paths[0],  # берем первый аудиофайл (или добавляем все для аугментаций)\n",
    "                        \"start\": terms_start,\n",
    "                        \"end\": terms_end,\n",
    "                        \"text\": \"\".join(term_words)  # Собираем слова в строку\n",
    "                    })\n",
    "\n",
    "                    # начинаем новый терм\n",
    "                    terms_start = segment_start_time\n",
    "                    terms_end = segment_end_time\n",
    "                    term_index += 1\n",
    "\n",
    "    # добавим файл с описанием монолога в формате для Whisper\n",
    "    with open(f'{monolog_path}/discriptions.json', 'w') as file:\n",
    "        json.dump(monolog_discr, file)\n"
   ],
   "id": "668d362698518c8a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "Получаем аудиофайлы длинны по 30 секунд и описание формата:\n",
    "{\n",
    "  \"speaker\": {\n",
    "    \"id\": \"1\",\n",
    "    \"name\": \"\"\n",
    "  },\n",
    "  \"start\": 0.0,\n",
    "  \"end\": 33.221,\n",
    "  \"terms\": [\n",
    "    {\n",
    "      \"audio_path\": \"monologue_0/term_0_aug0.wav\",\n",
    "      \"start\": 0.0,\n",
    "      \"end\": 30.0,\n",
    "      \"text\": \"...еще большую тревогу вызывает у меня американская политика..\"\n",
    "    },\n",
    "    {\n",
    "      \"audio_path\": \"monologue_0/term_1_aug0.wav\",\n",
    "      \"start\": 30.0,\n",
    "      \"end\": 33.221,\n",
    "      \"text\": \"...в отношении Ближнего Востока..\"\n",
    "    },\n",
    "    ...\n",
    "  ]\n",
    "}\n",
    "\n",
    "Важно отметить что способ разделения на слова через librosa.effects.split в данном примере не сработал как не сработал бы и pydub.silence.split_on_silence из за того что слова в .ogg аудио записи произносятся потоком почти без пауз между ними. Возможно получилось бы разделить их с помощью алгоритмов распознавания слов Speach to Text.\n",
    "\"\"\""
   ],
   "id": "674346eae41d1293",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "Для Whisper нам потребуется файл аннотаций формата\n",
    "[\n",
    "    {\"audio_filepath\": \"monologue_1/term_0_aug0.wav\", \"text\": \"...еще большую тревогу вызывает у меня американская политика..\"},\n",
    "    {\"audio_filepath\": \"monologue_1/term_1_aug0.wav\", \"text\": \"...в отношении Ближнего Востока..\"},\n",
    "    ...\n",
    "]\n",
    "\n",
    "Так как поле text у нас уже нормализованно а файлы wav не превосходят 30 секунд по длинне дополнительной обработки не потребуется\n",
    "\"\"\""
   ],
   "id": "c214112a0b6b2100",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import json\n",
    "\n",
    "MONOLOGUES_DIR = \"monologues\"\n",
    "# аннотации для whisper в формате jsonl\n",
    "OUTPUT_JSONL = \"whisper_dataset.jsonl\"\n",
    "\n",
    "# Сбор всех термов с их аудиофайлами и текстом\n",
    "entries = []\n",
    "\n",
    "for monologue_dir in MONOLOGUES_DIR.iterdir():\n",
    "    desc_path = f\"{MONOLOGUES_DIR}/{monologue_dir}/discriptions.json\"  # вычисляем пути до всех файлов описаний монологов\n",
    "\n",
    "    with open(desc_path, \"r\") as f:\n",
    "        description = json.load(f)\n",
    "\n",
    "    for term in description[\"terms\"]:\n",
    "        entries.append({\"audio_filepath\": term[\"audio_path\"], \"text\": term[\"text\"]})\n",
    "\n",
    "with open(OUTPUT_JSONL, \"w\") as f:\n",
    "    for entry in entries:\n",
    "        f.write(json.dumps(entry, ensure_ascii=False) + \"\\n\")"
   ],
   "id": "5128e7d74219fe8b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Задание 4\n",
    "\n",
    "LSTM с input_size = 128 и hidden_size = 256\n",
    "\n",
    "Сколько для одной LSTM ячейки обучаемых параметров"
   ],
   "id": "e3ed7bb6a0be1ed3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "LSTM ячейка состоит из 4 гейтов каждый из которых по сути яввляется линейным слоем.\n",
    "\n",
    "Каждый гейт имеет одну и ту же формулу sigmoid(Wf * Xt + Uf * Ht-1 + Bf)\n",
    "    здесь Xt размера input_size и Ht-1 размера hidden_size\n",
    "    следовательно Wf размера hidden_size * input_size, Uf размера hidden_size * hidden_size, Bf размера hidden_size\n",
    "\n",
    "получаем hidden_size * input_size + hidden_size * hidden_size + hidden_size = hidden_size * (input_size + hidden_size + 1) = 98560\n",
    "98560 * 4 = 394240 параметров суммаро для 4 гейтов в одной LSTM ячейке\n",
    "----------------------------------------------------------------------\n",
    "\n",
    "в torch.nn.LSTM реализованно два биаса для каждого гейта. один для входного слоя другой для скрытого что дает\n",
    "hidden_size * (input_size + hidden_size + 2) = 98816\n",
    "98816 * 4 = 395264 параметров суммаро для 4 гейтов в одной torch.nn.LSTM ячейке\n",
    "-------------------------------------------------------------------------------\n",
    "\"\"\""
   ],
   "id": "1f43dd2508de2326",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T09:14:09.421667Z",
     "start_time": "2025-04-18T09:14:08.118948Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "input_size = 128\n",
    "hidden_size = 256\n",
    "lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size)  # создаем LSTM блок"
   ],
   "id": "7fb2ebdf7b1479bd",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T09:14:09.429549Z",
     "start_time": "2025-04-18T09:14:09.426176Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Считаем количество параметров\n",
    "total_params = sum(p.numel() for p in lstm.parameters() if p.requires_grad)  # сумма параметров\n",
    "print(f\"Обучаемых параметров:\", total_params)"
   ],
   "id": "64734df9e3c4d3c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обучаемых параметров: 395264\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Задание 5\n",
    "\n",
    "Решаем задачу бинарной классификации аудиозаписей\n",
    "\n",
    "Имеется 100 записей:\n",
    "* 1 из класса C1\n",
    "* 99 из класса C0\n",
    "\n",
    "Обучен классификатор:\n",
    "* True Positive (Предсказали С1 при истинном С1) с вероятностью 0.9\n",
    "* False Positive (Предсказали С1 при истинном С0) с вероятностью 0.03\n",
    "\n",
    "Найти:\n",
    "1. Какова вероятность что случайную запись из датасета классификатор отнесет к C1\n",
    "2. Если случайная запись классифицирована как C1 какова вероятность что она действительно C1"
   ],
   "id": "67cd6992288f728c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "Заметим что вероятность получить класс C1 равна P(C1) = 0.01 а вероятность класса C0 P(C0) = 0.99\n",
    "Заметим что события С1 истинное и С0 ложное формируют полную группу гипотез\n",
    "\n",
    "1. По формуле полной вероятности\n",
    "    P(C1_predicted) = P(C1_predicted | C1_истинная) * P(C1_истинная) + P(C1_predicted | C0_истинная) * P(C0_истинная)\n",
    "    P(C1_predicted) = 0.9 * 0.01 + 0.03 * 0.99 = 0.0387 ~= 0.038\n",
    "                                                 --------------\n",
    "\n",
    "2. По теореме Байеса\n",
    "    P(C1_истинная | C1_predicted) =   P(C1_predicted | C1_истинная) * P(C1_истинная)                                                   =\n",
    "                                     _________________________________________________________________________________________________\n",
    "                                      P(C1_predicted | C1_истинная) * P(C1_истинная) + P(C1_predicted | C0_истинная) * P(C0_истинная)\n",
    "\n",
    "     = 0.9 * 0.01 / ( 0.9 * 0.01 + 0.03 * 0.99 ) = 0.2325581395 ~= 0.232\n",
    "                                                   --------------------\n",
    "\n",
    "Итого:\n",
    "1. Вероятность того что случайную запись из датасета классификатор отнесет к C1 ~= 0.038\n",
    "2. Вероятность того что случайная запись классифицирована как C1 и действительно является C1 ~= 0.232\n",
    "\"\"\""
   ],
   "id": "f1682e63f46219b1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Задание 6\n",
    "\n",
    "Для X1 .. Xn из множества вещественных чисел.\\\n",
    "Необходимо написать аналитическое решение для поиска значения b для минимизации sum( (Xi - b)^2 )\n"
   ],
   "id": "46ba4d252b4e406e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "Хотим минимизировать функцию потерь. Для вектора X найти некое b чтобы сумма квадратов разностей стала минимальной\n",
    "sum( (Xi - b)^2 )\n",
    "\n",
    "    Для этого воспользуемся градиентом приравненым к нулю т.е. точкой экстремума.\n",
    "    Т.к функция гладкая и выпуклая (парабола с ветками вверх) следовательно она имеет только одну точку экстремума являющуюся минимумом.\n",
    "    Т.е\n",
    "\n",
    "1. Раскрываем скобки под суммой\n",
    "sum( Xi^2 - 2 * Xi * b + b^2 )\n",
    "\n",
    "2. Раскроем по линейности суммы\n",
    "sum(Xi^2) - 2 * b * sum(Xi) + N * b^2\n",
    "\n",
    "3. найдем частную производную по b\n",
    "-2 * sum(Xi) + N * 2b\n",
    "\n",
    "4. Приравняем производную к нулю для поиска точки экстремума\n",
    "-2 * sum(Xi) + N * 2b = 0\n",
    "N * 2b = 2 * sum(Xi)\n",
    "2 * b = 2 * 1/N * sum(Xi)\n",
    "b = 1/N * sum(Xi)\n",
    "\n",
    "Ответ: (оказалось что выгоднее всего с точки зрения минимизации функции потерь выбирать среднее значение для b)\n",
    "b = 1/N * sum(Xi)\n",
    "---------------------------------------------------------------------------------------------------------------\n",
    "\"\"\""
   ],
   "id": "2eb7171bb027ca82",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Задание 7\n",
    "\n",
    "Образуют ли векторы:\n",
    "* x1 = [1, 0, 1]^T\n",
    "* x2 = [1, 1, 0]^T\n",
    "* x3 = [1, 1, 1]^T\n",
    "\n",
    "Базис векторного пространства в R^3. Написать аналитическое решение"
   ],
   "id": "ea7cbf297e85cb05"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "Проверим векторы на линейную зависимость.\n",
    "Если окажется что один из векторов представим как линейная комбинация двух других то вектора линейно зависимы -> не образуют базис в R^3\n",
    "\n",
    "1. Перепишем вектры как линейную комбинацию и приравняем к нулю:\n",
    "a * [1, 0, 1]^T + b * [1, 1, 0]^T + c * [1, 1, 1]^T = 0\n",
    "\n",
    "    тогда получится что любой вектор представим как линейная комбинация двух других со знаком минус например:\n",
    "    a * [1, 0, 1]^T + b * [1, 1, 0]^T = -c * [1, 1, 1]^T\n",
    "\n",
    "2. Составим и решим систему уравнений\n",
    "    [1]       [1]       [1]   [0]\n",
    "a * [0] + b * [1] + c * [1] = [0]\n",
    "    [1]       [0]       [1]   [0]\n",
    "\n",
    " /  a + b + c = 0\n",
    "<   b + c = 0\n",
    " \\  a + c = 0\n",
    "\n",
    "    из второй и третей строки получим:\n",
    "    b = -c\n",
    "    a = -c\n",
    "    подставим в первое:\n",
    "    -с -с + с= 0\n",
    "    т.е. -с = 0\n",
    "    Тогда единственное решение системы будет в точке [0, 0, 0]^T (a=b=c=0)\n",
    "\n",
    "    следовательно Векторы можно представить как линейную комбинацию друг друга только если все они нулевые.\n",
    "                  Значит они линейно независимы\n",
    "\n",
    "А это значит что векторы образуют базис векторного пространства в R^3\n",
    "----------------------------------------------------------------------\n",
    "\"\"\""
   ],
   "id": "8cf27e72124539d2",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
